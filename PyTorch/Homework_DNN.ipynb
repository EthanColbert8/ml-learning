{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a692e970-c403-4928-b861-3ede0a228305",
   "metadata": {},
   "source": [
    "# Homework: PyTorch Multi-Layer Perceptron\n",
    "\n",
    "This is a set of homework questions based on the `SimpleDNN.ipynb` tutorial, which will ask you to perform some experimentation and draw some insights about neural networks. We will use the same datasets as before, so make sure you still have those! It may also be beneficial to refer to that notebook if you're ever confused about the physics task at hand.\n",
    "\n",
    "As you work, feel free to insert cells into this notebook as needed. Please keep the overall structure (order of the problems, etc) consistent, but don't feel overly bound by the scaffolding laid out!\n",
    "\n",
    "To get started, we'll import the same tools we've used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6376ef07-3f3d-4d09-832f-20c0da176204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import cycle\n",
    "import numpy as np\n",
    "import vector\n",
    "import torch\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8643355-21dc-4f6c-b3ca-f54ccb58dd6b",
   "metadata": {},
   "source": [
    "To start, you should load in the datasets (and build `DataLoader`s) and re-create the model architecture you built from the tutorial. While I have no doubt you'll reference that code, try to make sure you're actually typing out at least a significant portion of it here. I've found that copy/pasting is often the enemy of knowledge retention!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aca436-6ed0-4f27-ba74-5e947877fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - load datasets and create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c50b4b-38f5-46ca-bf10-b37cd47be3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - define model class as subclass of torch.nn.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3d9d36-b62a-4f1b-bb76-fa6d0caf4dba",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "Now that you have a model class defined and some datasets, you should implement training! Here, we're going to do things a little differently than in the tutorial: you'll be wrapping all of the training process up neatly into a function! This will allow you to run multiple trainings easily within the notebook, which you'll be doing in later problems. Your function should accept as parameters:\n",
    "- an instance of your model class (the model to train)\n",
    "- an optimizer (instance of a class in the [`torch.optim`](https://docs.pytorch.org/docs/stable/optim.html) module)\n",
    "- a loss function (can be an instance of any subclass of `torch.nn.Module`, though will most likely be one of the losses that PyTorch implements)\n",
    "- a number of epochs to train\n",
    "- anything else you feel you'll need (or just want to include)\n",
    "\n",
    "It should then return the trained model.\n",
    "\n",
    "A couple of pointers for the design of this function:\n",
    "- Try to make it as self-contained as possible. This will likely involve adding additional parameters beyond the four mentioned above (what else did we need to know in order to set up our training?), but will pay off in the long run, as you can easily run trainings with a variety of configurations.\n",
    "- This function will likely spend more than a minute running when called (it takes time to train)! During that time, it might be nice to get some feedback that things are running as expected. Feel free to add `print` statements (or use other tools) to monitor your training progress!\n",
    "\n",
    "A simple signature has been included for you. When you finish, train a model! It might be a good idea to save them with `torch.jit.script(my_model).save(file_name)`. You can then load all your models and compare them very easily, with `my_model = torch.jit.load(file_name)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d142e-0550-4b52-bb9a-eb51e238c6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_my_model(model, optimizer, loss_fn, epochs=5):\n",
    "    \n",
    "    # Your code here - train the model!\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86abfbfb-3e51-44ac-a3d0-ad5fa736bac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - call your function and train!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c39ad5-a066-499a-9e01-caf7eeca9f15",
   "metadata": {},
   "source": [
    "### Problem 2: Model Size\n",
    "\n",
    "Now that we can create and train a variety of models easily, let's investigate a major aspect (and sometimes pain point) in machine learning: how does the performance of our model vary as its size changes? Train at least 4 different models (for at least 5 epochs each) and examine their performance on the validation (or testing) dataset. Which one performed the best? Write down your observations in markdown cells as you go, and try to compare performance directly (perhaps even in a plot?) among the different trainings you ran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90259769-7db7-46bc-8ff5-a869eaa1ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400d5164-41a9-40e9-a75d-226808f16a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c2fa1f-7b4e-452b-b1e2-710e01249fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93f149-f503-4256-9deb-61b3ddeef57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f16e497-35a8-4e3b-b631-7476d7612515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915e706f-9654-47c7-8c55-7f21d69cd9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3cf780-23a9-47c4-b4aa-fe84d1c14fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95293f8-4046-4fb8-806a-ad1a3cfbd3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178ee250-1c05-4118-bcf3-80c9be27be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison and summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01231171-ef66-4fc2-989f-1b9c09deb5fb",
   "metadata": {},
   "source": [
    "### Problem 3: Our Input Data\n",
    "\n",
    "To understand our problem a little better, let's look a bit more closely at what we're giving the model.\n",
    "\n",
    "#### Part 3a: Taking a Look\n",
    "\n",
    "Plot histograms of several of the observables that serve as inputs to our model. You should at least plot the $p_x$, $p_z$, and $E$ of the _first jet_ and _lepton_, and the $p_x$ and $p_y$ of the missing transverse energy. What do you see? Do all the variables lie in about the same range, or are their domains different? What about their distributions? Summarize your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33e076-8c0c-459d-bde0-b7177d0ae7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - make some plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0059cf7-27cc-46a4-be45-0e12702fc4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary - what did you find?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1165452-0dc0-4286-aaa0-dc81540d2492",
   "metadata": {},
   "source": [
    "#### Part 3b: Standardization\n",
    "\n",
    "Hopefully you saw that the distributions of the various quantities we pass to the model can be quite different from each other! Neural networks can sometimes [train more easily](https://doi.org/10.1016/0305-0483(96)00010-2) (and thus reach better performance) when all of the features have roughly the same range of values. So, we should try _standardizing_ our input features, so that they all lie on a similar range. The most straightforward way to do this is by taking each feature, subtracting its mean, and dividing by its standard deviation:\n",
    "\n",
    "$$ x_{i,j} \\leftarrow \\frac{x_{i,j} - \\langle x_i \\rangle}{\\sigma_i} $$\n",
    "\n",
    "where $i$ indexes over the different features (so $\\langle x_i \\rangle$ is the mean of the $i$th feature) and $j$ indexes over the samples in our dataset. This transformation will map any normal (Gaussian) distribution to the _standard normal distribution_ (Gaussian with $\\mu=0$ and $\\sigma=1$). On other distributions, it will preserve the shape, but shift it to be centered around zero and squeeze the values into a (usually) smaller range. Is this desirable for us? Try it and see!\n",
    "\n",
    "The Scikit-Learn library provides a variety of methods for data standardization in their [preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html) module. The method I described above is implemented in the [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) class. You can use these if you wish, but be aware that you'll need to convert the PyTorch tensors from the datasets to Numpy arrays (you can use [`torch.Tensor.numpy()`](https://docs.pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) for this), pass them through the scalers, then convert them back to tensors (using [`torch.as_tensor()`](https://docs.pytorch.org/docs/stable/generated/torch.as_tensor.html#torch.as_tensor) or similar).\n",
    "\n",
    "Regardless of how you accomplish it, try to standardize the input features and train a model with them. If you expanded the parameter list in your training function to include the dataloaders, you'll be able to just create new dataloaders with your transformed inputs and pass them in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73917042-e1ff-464f-b9de-7ed43155e21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing # Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0796ce-2ac6-4382-80f7-9057b4bb7022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647fa61d-e033-4446-b686-43b380052771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87198e2d-c61f-444f-98a9-54b3cf312991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - evaluation and conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b303e2ff-d4e0-426c-b70b-aebbdbeb7514",
   "metadata": {},
   "source": [
    "#### Part 3c: Standardizing Outputs\n",
    "\n",
    "Just like input features, _output features_ can also be standardized. This is simple in training, but complicates evaluation a bit - in order to interpret the predictions your model makes, you'll need to _invert the transformation_. Here's where the Scikit-Learn classes can come in handy - they implement an `inverse_transform()` method that can do this inversion easily. Try training with standardized outputs, both with and without standardizing inputs. Which combination performs the best? Why might this be the case?\n",
    "\n",
    "Hint: if you're having trouble getting your tensor(s) of model predictions into Numpy arrays to invert the scaling, you may need to use something like `output_tensor.detach().to(\"cpu\").numpy()`. This detaches your tensor from PyTorch's computational graph, moves the data to CPU memory if it's on the GPU, and _only then_ converts it to Numpy. A slightly less safe alternative is `output_tensor.numpy(force=True)`, which does these things and a couple of others to ensure Numpy can work with the data in the tensor.\n",
    "\n",
    "Note: if you already standardized your output features along with your inputs before, that's totally fine, no need to change that! Just train with only inputs (and only outputs) standardized now, and comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2173ea-62b9-4d57-8bd3-b99ceea891ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - standardize output features and make new dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd005316-78f8-4688-b752-d9adcb265200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933b66d-fb02-45aa-8f23-1836147243d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation and conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d96f207-1c0e-4aee-9931-bcafcb121e74",
   "metadata": {},
   "source": [
    "### Problem 4: Other Training Settings\n",
    "\n",
    "As a final problem, experiment with other _hyperparameters_ (settings for our training process). Run several trainings, varying at least two of these things:\n",
    "- Change the _batch size_ to be larger or smaller (create new dataloaders using the same datasets). How big do batches need to be?\n",
    "- Change the learning rate (when you create the optimizer). Try several values and try to find the best one! Does this optimal value depend on the batch size? Why might this be?\n",
    "- Use a different loss function than you have so far. Try [MSE](https://docs.pytorch.org/docs/stable/generated/torch.nn.MSELoss.html), [L1 Loss (MAE)](https://docs.pytorch.org/docs/stable/generated/torch.nn.L1Loss), and [Huber loss](https://docs.pytorch.org/docs/2.8/generated/torch.nn.HuberLoss.html), all of which are common in regression problems like this.\n",
    "\n",
    "Compare the results of your different trainings. Were any of the optimal settings surprising to you? Why (or why not)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7760c24f-52ad-493a-8132-ec3eee70cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - many trainings!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ce9abc-8043-452f-a654-382eb8503f36",
   "metadata": {},
   "source": [
    "You're done, yay!\n",
    "\n",
    "A couple of final notes on that last problem:\n",
    "1. I just mentioned a few of the standard loss functions implemented in PyTorch, but you can implement _custom_ loss functions as well! They're subclasses of `torch.nn.Module`, just like the models themselves. This, along with model architecture, is one of the biggest \"knobs\" that researchers play with to improve model training (check out [multi-objective optimization](https://indico.cern.ch/event/1299889/contributions/5465272/attachments/2773733/4833542/MDMM%20lecture.pdf) for some cool stuff in this arena).\n",
    "2. This last problem was likely your first stumbling steps towards the practice of _hyperparameter optimization_. This is a big deal in machine learning, and doing it systematically is often a large effort (and large computational cost) for ML-based research projects. One package that exists to ease the effort is [Optuna](https://optuna.readthedocs.io/en/stable/), a very flexible framework for general optimization problems. I've used it a lot in the past, and it greatly simplifies the process of finding good hyperparameters amidst a huge search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc1c91e-ebe4-4f40-992d-915c3f8e4cca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bumblebee]",
   "language": "python",
   "name": "conda-env-bumblebee-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
