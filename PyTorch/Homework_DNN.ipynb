{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a692e970-c403-4928-b861-3ede0a228305",
   "metadata": {},
   "source": [
    "# Homework: PyTorch Multi-Layer Perceptron\n",
    "\n",
    "This is a set of homework questions based on the `SimpleDNN.ipynb` tutorial, which will ask you to perform some experimentation and draw some insights about neural networks. We will use the same datasets as before, so make sure you still have those! It may also be beneficial to refer to that notebook if you're ever confused about the physics task at hand.\n",
    "\n",
    "As you work, feel free to insert cells into this notebook as needed. Please keep the overall structure (order of the problems, etc) consistent, but don't feel overly bound by the scaffolding laid out!\n",
    "\n",
    "To get started, we'll import the same tools we've used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6376ef07-3f3d-4d09-832f-20c0da176204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import cycle\n",
    "import numpy as np\n",
    "import vector\n",
    "import torch\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8643355-21dc-4f6c-b3ca-f54ccb58dd6b",
   "metadata": {},
   "source": [
    "To start, you should load in the datasets (and build `DataLoader`s) and re-create the model architecture you built from the tutorial. While I have no doubt you'll reference that code, try to make sure you're actually typing out at least a significant portion of it here. I've found that copy/pasting is often the enemy of knowledge retention!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aca436-6ed0-4f27-ba74-5e947877fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - load datasets and create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c50b4b-38f5-46ca-bf10-b37cd47be3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - define model class as subclass of torch.nn.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3d9d36-b62a-4f1b-bb76-fa6d0caf4dba",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "Now that you have a model class defined and some datasets, you should implement training! Here, we're going to do things a little differently than in the tutorial: you'll be wrapping all of the training process up neatly into a function! This will allow you to run multiple trainings easily within the notebook, which you'll be doing in later problems. Your function should accept as parameters:\n",
    "- an instance of your model class (the model to train)\n",
    "- an optimizer (instance of a class in the [`torch.optim`](https://docs.pytorch.org/docs/stable/optim.html) module)\n",
    "- a loss function (can be an instance of any subclass of `torch.nn.Module`, though will most likely be one of the losses that PyTorch implements)\n",
    "- a number of epochs to train\n",
    "- anything else you feel you'll need (or just want to include)\n",
    "\n",
    "It should then return the trained model.\n",
    "\n",
    "A couple of pointers for the design of this function:\n",
    "- Try to make it as self-contained as possible. This will likely involve adding additional parameters beyond the four mentioned above (what else did we need to know in order to set up our training?), but will pay off in the long run, as you can easily run trainings with a variety of configurations.\n",
    "- This function will likely spend more than a minute running when called (it takes time to train)! During that time, it might be nice to get some feedback that things are running as expected. Feel free to add `print` statements (or use other tools) to monitor your training progress!\n",
    "\n",
    "A simple signature has been included for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d142e-0550-4b52-bb9a-eb51e238c6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_my_model(model, optimizer, loss_fn, epochs=5):\n",
    "    \n",
    "    # Your code here - train the model!\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c39ad5-a066-499a-9e01-caf7eeca9f15",
   "metadata": {},
   "source": [
    "### Problem 2: Model Size\n",
    "\n",
    "Now that we can create and train a variety of models easily, let's investigate a major aspect (and sometimes pain point) in machine learning: how does the performance of our model vary as its size changes? Train at least 4 different models (for at least 5 epochs each) and examine their performance on the validation (or testing) dataset. Which one performed the best? Write down your observations in markdown cells as you go, and try to compare performance directly (perhaps even in a plot?) among the different trainings you ran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90259769-7db7-46bc-8ff5-a869eaa1ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400d5164-41a9-40e9-a75d-226808f16a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c2fa1f-7b4e-452b-b1e2-710e01249fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93f149-f503-4256-9deb-61b3ddeef57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f16e497-35a8-4e3b-b631-7476d7612515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915e706f-9654-47c7-8c55-7f21d69cd9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3cf780-23a9-47c4-b4aa-fe84d1c14fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95293f8-4046-4fb8-806a-ad1a3cfbd3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178ee250-1c05-4118-bcf3-80c9be27be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison and summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01231171-ef66-4fc2-989f-1b9c09deb5fb",
   "metadata": {},
   "source": [
    "### Problem 3: Our Input Data\n",
    "\n",
    "To understand our problem a little better, let's look a bit more closely at what we're giving the model.\n",
    "\n",
    "#### Part 3A: Taking a Look\n",
    "\n",
    "Plot histograms of several of the observables that serve as inputs to our model. You should at least plot the $p_x$, $p_z$, and $E$ of the _first jet_ and _lepton_, and the $p_x$ and $p_y$ of the missing transverse energy. What do you see? Do all the variables lie in about the same range, or are their domains different? What about their distributions? Summarize your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33e076-8c0c-459d-bde0-b7177d0ae7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - make some plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0059cf7-27cc-46a4-be45-0e12702fc4df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac35be8-fe63-4ce8-8190-3d5831ce7877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bumblebee]",
   "language": "python",
   "name": "conda-env-bumblebee-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
